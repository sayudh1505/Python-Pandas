{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Installing Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Making Manual Data and Data Framing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Salary\n",
      "0     Yash   12    2000\n",
      "1    Kunal   23   33000\n",
      "2  Supriya   32    5000\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\": [\"Yash\", \"Kunal\", \"Supriya\"],\n",
    "    \"Age\": [12, 23, 32],\n",
    "    \"Salary\": [2000, 33000, 5000],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Reading and Printing a CSV File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rank   movie_id                     title  year  \\\n",
      "0       1  tt0111161  The Shawshank Redemption  1994   \n",
      "1       2  tt0068646             The Godfather  1972   \n",
      "2       3  tt0468569           The Dark Knight  2008   \n",
      "3       4  tt0071562     The Godfather Part II  1974   \n",
      "4       5  tt0050083              12 Angry Men  1957   \n",
      "..    ...        ...                       ...   ...   \n",
      "245   246  tt0071411               Dersu Uzala  1975   \n",
      "246   247  tt1454029                  The Help  2011   \n",
      "247   248  tt0103639                   Aladdin  1992   \n",
      "248   249  tt0083987                    Gandhi  1982   \n",
      "249   250  tt0099348        Dances with Wolves  1990   \n",
      "\n",
      "                                     link imbd_votes  imbd_rating certificate  \\\n",
      "0    https://www.imdb.com/title/tt0111161  2,711,075          9.3           R   \n",
      "1    https://www.imdb.com/title/tt0068646  1,882,829          9.2           R   \n",
      "2    https://www.imdb.com/title/tt0468569  2,684,051          9.0       PG-13   \n",
      "3    https://www.imdb.com/title/tt0071562  1,285,350          9.0           R   \n",
      "4    https://www.imdb.com/title/tt0050083    800,954          9.0    Approved   \n",
      "..                                    ...        ...          ...         ...   \n",
      "245  https://www.imdb.com/title/tt0071411     31,167          8.2           G   \n",
      "246  https://www.imdb.com/title/tt1454029    466,011          8.1       PG-13   \n",
      "247  https://www.imdb.com/title/tt0103639    429,219          8.0           G   \n",
      "248  https://www.imdb.com/title/tt0083987    234,688          8.0          PG   \n",
      "249  https://www.imdb.com/title/tt0099348    271,823          8.0       PG-13   \n",
      "\n",
      "    duration                       genre  ...          director_id  \\\n",
      "0     2h 22m                       Drama  ...            nm0001104   \n",
      "1     2h 55m                 Crime,Drama  ...            nm0000338   \n",
      "2     2h 32m          Action,Crime,Drama  ...            nm0634240   \n",
      "3     3h 22m                 Crime,Drama  ...            nm0000338   \n",
      "4     1h 36m                 Crime,Drama  ...            nm0001486   \n",
      "..       ...                         ...  ...                  ...   \n",
      "245   2h 22m   Adventure,Biography,Drama  ...            nm0000041   \n",
      "246   2h 26m                       Drama  ...            nm0853238   \n",
      "247   1h 30m  Animation,Adventure,Comedy  ...  nm0166256,nm0615780   \n",
      "248   3h 11m     Biography,Drama,History  ...            nm0000277   \n",
      "249    3h 1m     Adventure,Drama,Western  ...            nm0000126   \n",
      "\n",
      "                director_name  \\\n",
      "0              Frank Darabont   \n",
      "1        Francis Ford Coppola   \n",
      "2           Christopher Nolan   \n",
      "3        Francis Ford Coppola   \n",
      "4                Sidney Lumet   \n",
      "..                        ...   \n",
      "245            Akira Kurosawa   \n",
      "246               Tate Taylor   \n",
      "247  Ron Clements,John Musker   \n",
      "248      Richard Attenborough   \n",
      "249             Kevin Costner   \n",
      "\n",
      "                                             writer_id  \\\n",
      "0                                  nm0000175,nm0001104   \n",
      "1                                  nm0701374,nm0000338   \n",
      "2    tt0468569,nm0634300,nm0634240,nm0275286,tt0468569   \n",
      "3                                  nm0000338,nm0701374   \n",
      "4                                            nm0741627   \n",
      "..                                                 ...   \n",
      "245                      nm0000041,nm0619330,nm0037539   \n",
      "246                                nm0853238,nm3543826   \n",
      "247  tt0103639,nm0166256,nm0615780,nm0254645,tt0103639   \n",
      "248                                          nm0109300   \n",
      "249                                          nm0086658   \n",
      "\n",
      "                                           writer_name  \\\n",
      "0                          Stephen King,Frank Darabont   \n",
      "1                      Mario Puzo,Francis Ford Coppola   \n",
      "2    Writers,Jonathan Nolan,Christopher Nolan,David...   \n",
      "3                      Francis Ford Coppola,Mario Puzo   \n",
      "4                                        Reginald Rose   \n",
      "..                                                 ...   \n",
      "245      Akira Kurosawa,Yuriy Nagibin,Vladimir Arsenev   \n",
      "246                       Tate Taylor,Kathryn Stockett   \n",
      "247      Writers,Ron Clements,John Musker,Ted Elliott,   \n",
      "248                                        John Briley   \n",
      "249                                      Michael Blake   \n",
      "\n",
      "                                             storyline  \\\n",
      "0    Over the course of several years, two convicts...   \n",
      "1    The aging patriarch of an organized crime dyna...   \n",
      "2    When the menace known as the Joker wreaks havo...   \n",
      "3    The early life and career of Vito Corleone in ...   \n",
      "4    The jury in a New York City murder trial is fr...   \n",
      "..                                                 ...   \n",
      "245  The Russian army sends an explorer on an exped...   \n",
      "246  An aspiring author during the civil rights mov...   \n",
      "247  A kindhearted street urchin and a power-hungry...   \n",
      "248  The life of the lawyer who became the famed le...   \n",
      "249  Lieutenant John Dunbar, assigned to a remote w...   \n",
      "\n",
      "                                               user_id  \\\n",
      "0    ur16161013,ur15311310,ur0265899,ur16117882,ur1...   \n",
      "1    ur24740649,ur86182727,ur15794099,ur15311310,ur...   \n",
      "2    ur87850731,ur1293485,ur129557514,ur12449122,ur...   \n",
      "3    ur0176092,ur0688559,ur92260614,ur0200644,ur117...   \n",
      "4    ur1318549,ur0643062,ur0688559,ur20552756,ur945...   \n",
      "..                                                 ...   \n",
      "245  ur0453068,ur0491610,ur3212364,ur2488512,ur1911...   \n",
      "246  ur0806494,ur1391596,ur24207576,ur2955724,ur221...   \n",
      "247  ur1293485,ur1416505,ur4445210,ur4234119,ur0909...   \n",
      "248  ur0954062,ur0688559,ur0176092,ur0940950,ur2620...   \n",
      "249  ur66111139,ur16161013,ur20597848,ur1413169,ur5...   \n",
      "\n",
      "                                             user_name  \\\n",
      "0    hitchcockthelegend,Sleepin_Dragon,EyeDunno,ale...   \n",
      "1    CalRhys,andrewburgereviews,gogoschka-1,Sleepin...   \n",
      "2    MrHeraclius,Smells_Like_Cheese,dseferaj,little...   \n",
      "3    Nazi_Fighter_David,tfrizzell,umunir-36959,DanB...   \n",
      "4    uds3,tedg,tfrizzell,TheLittleSongbird,henrique...   \n",
      "..                                                 ...   \n",
      "245  Quinoa1984,howard.schumann,Spondonman,claudio_...   \n",
      "246  ferguson-6,JohnDeSando,taylor_king-890-815491,...   \n",
      "247  Smells_Like_Cheese,Boba_Fett1138,ccthemovieman...   \n",
      "248  khatcher-2,tfrizzell,Nazi_Fighter_David,Rod-88...   \n",
      "249  gbill-74877,hitchcockthelegend,bheadher,Philip...   \n",
      "\n",
      "                                             review_id  \\\n",
      "0    rw2284594,rw6606154,rw1221355,rw1822343,rw1288...   \n",
      "1    rw3038370,rw4756923,rw4059579,rw6568526,rw1897...   \n",
      "2    rw5478826,rw1914442,rw6606026,rw1917099,rw5170...   \n",
      "3    rw0135607,rw0135487,rw5049900,rw0135526,rw0135...   \n",
      "4    rw0060044,rw0060025,rw0060034,rw2262425,rw5448...   \n",
      "..                                                 ...   \n",
      "245  rw1024676,rw0134934,rw1122059,rw2168879,rw2373...   \n",
      "246  rw2473566,rw2472337,rw2472299,rw2697863,rw2488...   \n",
      "247  rw0302749,rw0950861,rw1571053,rw2534639,rw0302...   \n",
      "248  rw0194126,rw1179566,rw1106866,rw0194132,rw0194...   \n",
      "249  rw6808367,rw2322324,rw4656461,rw0959913,rw1379...   \n",
      "\n",
      "                                          review_title  \\\n",
      "0    Some birds aren't meant to be caged.,An incred...   \n",
      "1    The Pinnacle Of Flawless Films!,An offer so go...   \n",
      "2    The Dark Knight,The Batman of our dreams! So m...   \n",
      "3    Breathtaking in its scope and tragic grandeur....   \n",
      "4    The over-used term \"classic movie\" really come...   \n",
      "..                                                 ...   \n",
      "245  a tribute to the endurance of man and nature, ...   \n",
      "246  Minny Don't Burn Chicken,Ready to burst . . .,...   \n",
      "247  I'd put it in with the Disney classics,Great s...   \n",
      "248  Took nearly twenty years to make - not a singl...   \n",
      "249  Fantastic,It is the trail of a true human bein...   \n",
      "\n",
      "                                        review_content  \n",
      "0    The Shawshank Redemption is written and direct...  \n",
      "1    'The Godfather' is the pinnacle of flawless fi...  \n",
      "2    Confidently directed, dark, brooding, and pack...  \n",
      "3    Coppola's masterpiece is rivaled only by \"The ...  \n",
      "4    This once-in-a-generation masterpiece simply h...  \n",
      "..                                                 ...  \n",
      "245  For a variety of reasons (that are well known ...  \n",
      "246  Greetings again from the darkness. The film is...  \n",
      "247  Aladdin is such an awesome move that still get...  \n",
      "248  Here indeed is one of the great films of the 2...  \n",
      "249  It's hard to think of blockbuster films that p...  \n",
      "\n",
      "[250 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    r\"C:\\Users\\sayud\\OneDrive\\Desktop\\Data Science\\Pandas\\Datasets-main\\movies.csv\"\n",
    ")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Data Framing Readed CSV File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rank   movie_id                     title  year  \\\n",
      "0       1  tt0111161  The Shawshank Redemption  1994   \n",
      "1       2  tt0068646             The Godfather  1972   \n",
      "2       3  tt0468569           The Dark Knight  2008   \n",
      "3       4  tt0071562     The Godfather Part II  1974   \n",
      "4       5  tt0050083              12 Angry Men  1957   \n",
      "..    ...        ...                       ...   ...   \n",
      "245   246  tt0071411               Dersu Uzala  1975   \n",
      "246   247  tt1454029                  The Help  2011   \n",
      "247   248  tt0103639                   Aladdin  1992   \n",
      "248   249  tt0083987                    Gandhi  1982   \n",
      "249   250  tt0099348        Dances with Wolves  1990   \n",
      "\n",
      "                                     link imbd_votes  imbd_rating certificate  \\\n",
      "0    https://www.imdb.com/title/tt0111161  2,711,075          9.3           R   \n",
      "1    https://www.imdb.com/title/tt0068646  1,882,829          9.2           R   \n",
      "2    https://www.imdb.com/title/tt0468569  2,684,051          9.0       PG-13   \n",
      "3    https://www.imdb.com/title/tt0071562  1,285,350          9.0           R   \n",
      "4    https://www.imdb.com/title/tt0050083    800,954          9.0    Approved   \n",
      "..                                    ...        ...          ...         ...   \n",
      "245  https://www.imdb.com/title/tt0071411     31,167          8.2           G   \n",
      "246  https://www.imdb.com/title/tt1454029    466,011          8.1       PG-13   \n",
      "247  https://www.imdb.com/title/tt0103639    429,219          8.0           G   \n",
      "248  https://www.imdb.com/title/tt0083987    234,688          8.0          PG   \n",
      "249  https://www.imdb.com/title/tt0099348    271,823          8.0       PG-13   \n",
      "\n",
      "    duration                       genre  ...          director_id  \\\n",
      "0     2h 22m                       Drama  ...            nm0001104   \n",
      "1     2h 55m                 Crime,Drama  ...            nm0000338   \n",
      "2     2h 32m          Action,Crime,Drama  ...            nm0634240   \n",
      "3     3h 22m                 Crime,Drama  ...            nm0000338   \n",
      "4     1h 36m                 Crime,Drama  ...            nm0001486   \n",
      "..       ...                         ...  ...                  ...   \n",
      "245   2h 22m   Adventure,Biography,Drama  ...            nm0000041   \n",
      "246   2h 26m                       Drama  ...            nm0853238   \n",
      "247   1h 30m  Animation,Adventure,Comedy  ...  nm0166256,nm0615780   \n",
      "248   3h 11m     Biography,Drama,History  ...            nm0000277   \n",
      "249    3h 1m     Adventure,Drama,Western  ...            nm0000126   \n",
      "\n",
      "                director_name  \\\n",
      "0              Frank Darabont   \n",
      "1        Francis Ford Coppola   \n",
      "2           Christopher Nolan   \n",
      "3        Francis Ford Coppola   \n",
      "4                Sidney Lumet   \n",
      "..                        ...   \n",
      "245            Akira Kurosawa   \n",
      "246               Tate Taylor   \n",
      "247  Ron Clements,John Musker   \n",
      "248      Richard Attenborough   \n",
      "249             Kevin Costner   \n",
      "\n",
      "                                             writer_id  \\\n",
      "0                                  nm0000175,nm0001104   \n",
      "1                                  nm0701374,nm0000338   \n",
      "2    tt0468569,nm0634300,nm0634240,nm0275286,tt0468569   \n",
      "3                                  nm0000338,nm0701374   \n",
      "4                                            nm0741627   \n",
      "..                                                 ...   \n",
      "245                      nm0000041,nm0619330,nm0037539   \n",
      "246                                nm0853238,nm3543826   \n",
      "247  tt0103639,nm0166256,nm0615780,nm0254645,tt0103639   \n",
      "248                                          nm0109300   \n",
      "249                                          nm0086658   \n",
      "\n",
      "                                           writer_name  \\\n",
      "0                          Stephen King,Frank Darabont   \n",
      "1                      Mario Puzo,Francis Ford Coppola   \n",
      "2    Writers,Jonathan Nolan,Christopher Nolan,David...   \n",
      "3                      Francis Ford Coppola,Mario Puzo   \n",
      "4                                        Reginald Rose   \n",
      "..                                                 ...   \n",
      "245      Akira Kurosawa,Yuriy Nagibin,Vladimir Arsenev   \n",
      "246                       Tate Taylor,Kathryn Stockett   \n",
      "247      Writers,Ron Clements,John Musker,Ted Elliott,   \n",
      "248                                        John Briley   \n",
      "249                                      Michael Blake   \n",
      "\n",
      "                                             storyline  \\\n",
      "0    Over the course of several years, two convicts...   \n",
      "1    The aging patriarch of an organized crime dyna...   \n",
      "2    When the menace known as the Joker wreaks havo...   \n",
      "3    The early life and career of Vito Corleone in ...   \n",
      "4    The jury in a New York City murder trial is fr...   \n",
      "..                                                 ...   \n",
      "245  The Russian army sends an explorer on an exped...   \n",
      "246  An aspiring author during the civil rights mov...   \n",
      "247  A kindhearted street urchin and a power-hungry...   \n",
      "248  The life of the lawyer who became the famed le...   \n",
      "249  Lieutenant John Dunbar, assigned to a remote w...   \n",
      "\n",
      "                                               user_id  \\\n",
      "0    ur16161013,ur15311310,ur0265899,ur16117882,ur1...   \n",
      "1    ur24740649,ur86182727,ur15794099,ur15311310,ur...   \n",
      "2    ur87850731,ur1293485,ur129557514,ur12449122,ur...   \n",
      "3    ur0176092,ur0688559,ur92260614,ur0200644,ur117...   \n",
      "4    ur1318549,ur0643062,ur0688559,ur20552756,ur945...   \n",
      "..                                                 ...   \n",
      "245  ur0453068,ur0491610,ur3212364,ur2488512,ur1911...   \n",
      "246  ur0806494,ur1391596,ur24207576,ur2955724,ur221...   \n",
      "247  ur1293485,ur1416505,ur4445210,ur4234119,ur0909...   \n",
      "248  ur0954062,ur0688559,ur0176092,ur0940950,ur2620...   \n",
      "249  ur66111139,ur16161013,ur20597848,ur1413169,ur5...   \n",
      "\n",
      "                                             user_name  \\\n",
      "0    hitchcockthelegend,Sleepin_Dragon,EyeDunno,ale...   \n",
      "1    CalRhys,andrewburgereviews,gogoschka-1,Sleepin...   \n",
      "2    MrHeraclius,Smells_Like_Cheese,dseferaj,little...   \n",
      "3    Nazi_Fighter_David,tfrizzell,umunir-36959,DanB...   \n",
      "4    uds3,tedg,tfrizzell,TheLittleSongbird,henrique...   \n",
      "..                                                 ...   \n",
      "245  Quinoa1984,howard.schumann,Spondonman,claudio_...   \n",
      "246  ferguson-6,JohnDeSando,taylor_king-890-815491,...   \n",
      "247  Smells_Like_Cheese,Boba_Fett1138,ccthemovieman...   \n",
      "248  khatcher-2,tfrizzell,Nazi_Fighter_David,Rod-88...   \n",
      "249  gbill-74877,hitchcockthelegend,bheadher,Philip...   \n",
      "\n",
      "                                             review_id  \\\n",
      "0    rw2284594,rw6606154,rw1221355,rw1822343,rw1288...   \n",
      "1    rw3038370,rw4756923,rw4059579,rw6568526,rw1897...   \n",
      "2    rw5478826,rw1914442,rw6606026,rw1917099,rw5170...   \n",
      "3    rw0135607,rw0135487,rw5049900,rw0135526,rw0135...   \n",
      "4    rw0060044,rw0060025,rw0060034,rw2262425,rw5448...   \n",
      "..                                                 ...   \n",
      "245  rw1024676,rw0134934,rw1122059,rw2168879,rw2373...   \n",
      "246  rw2473566,rw2472337,rw2472299,rw2697863,rw2488...   \n",
      "247  rw0302749,rw0950861,rw1571053,rw2534639,rw0302...   \n",
      "248  rw0194126,rw1179566,rw1106866,rw0194132,rw0194...   \n",
      "249  rw6808367,rw2322324,rw4656461,rw0959913,rw1379...   \n",
      "\n",
      "                                          review_title  \\\n",
      "0    Some birds aren't meant to be caged.,An incred...   \n",
      "1    The Pinnacle Of Flawless Films!,An offer so go...   \n",
      "2    The Dark Knight,The Batman of our dreams! So m...   \n",
      "3    Breathtaking in its scope and tragic grandeur....   \n",
      "4    The over-used term \"classic movie\" really come...   \n",
      "..                                                 ...   \n",
      "245  a tribute to the endurance of man and nature, ...   \n",
      "246  Minny Don't Burn Chicken,Ready to burst . . .,...   \n",
      "247  I'd put it in with the Disney classics,Great s...   \n",
      "248  Took nearly twenty years to make - not a singl...   \n",
      "249  Fantastic,It is the trail of a true human bein...   \n",
      "\n",
      "                                        review_content  \n",
      "0    The Shawshank Redemption is written and direct...  \n",
      "1    'The Godfather' is the pinnacle of flawless fi...  \n",
      "2    Confidently directed, dark, brooding, and pack...  \n",
      "3    Coppola's masterpiece is rivaled only by \"The ...  \n",
      "4    This once-in-a-generation masterpiece simply h...  \n",
      "..                                                 ...  \n",
      "245  For a variety of reasons (that are well known ...  \n",
      "246  Greetings again from the darkness. The film is...  \n",
      "247  Aladdin is such an awesome move that still get...  \n",
      "248  Here indeed is one of the great films of the 2...  \n",
      "249  It's hard to think of blockbuster films that p...  \n",
      "\n",
      "[250 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.For Reading xlsx(Excel File)\n",
    "Firstly we need to download openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\sayud\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\sayud\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[1000 rows x 14 columns]\n",
      "       EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\n",
    "    r\"C:\\Users\\sayud\\OneDrive\\Desktop\\Data Science\\Pandas\\Datasets-main\\ESD.xlsx\"\n",
    ")\n",
    "\n",
    "print(data)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Exploring the big data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\n",
    "    r\"C:\\Users\\sayud\\OneDrive\\Desktop\\Data Science\\Pandas\\Datasets-main\\ESD.xlsx\"\n",
    ")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.For exploring starting or ending specific(n) of big data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date  \n",
      "0     0.15  United States    Seattle 2021-10-16  \n",
      "1     0.00          China  Chongqing        NaT  \n",
      "2     0.20  United States    Chicago        NaT  \n",
      "3     0.07  United States    Chicago        NaT  \n",
      "4     0.00  United States    Phoenix        NaT  \n",
      "5     0.00          China  Chongqing        NaT  \n",
      "6     0.10  United States    Phoenix        NaT  \n",
      "7     0.00  United States      Miami 2021-05-20  \n",
      "8     0.06  United States     Austin        NaT  \n",
      "9     0.00  United States    Chicago        NaT  \n",
      "       EEID          Full Name             Job Title       Department  \\\n",
      "990  E01578       Anthony Hong            Sr. Manger               IT   \n",
      "991  E03430        Leo Herrera  Sr. Business Partner  Human Resources   \n",
      "992  E03058      Robert Wright   Technical Architect               IT   \n",
      "993  E04762  Audrey Richardson              Director               IT   \n",
      "994  E01148     Scarlett Kumar       Systems Analyst               IT   \n",
      "995  E03094       Wesley Young           Sr. Analyst        Marketing   \n",
      "996  E01909       Lillian Khan               Analyst          Finance   \n",
      "997  E04398        Oliver Yang              Director        Marketing   \n",
      "998  E02521        Lily Nguyen           Sr. Analyst          Finance   \n",
      "999  E03545        Sofia Cheng        Vice President       Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "990  Research & Development    Male      Asian   37 2010-11-29         146961   \n",
      "991  Research & Development    Male     Latino   48 1998-04-22          85369   \n",
      "992           Manufacturing    Male  Caucasian   30 2015-06-14          67489   \n",
      "993           Manufacturing  Female  Caucasian   46 2018-10-06         166259   \n",
      "994               Corporate  Female      Asian   55 2009-01-07          47032   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country      City  Exit Date  \n",
      "990     0.11  United States  Columbus        NaT  \n",
      "991     0.00         Brazil    Manaus 2004-11-27  \n",
      "992     0.00  United States   Chicago        NaT  \n",
      "993     0.17  United States   Chicago        NaT  \n",
      "994     0.00  United States  Columbus        NaT  \n",
      "995     0.00  United States  Columbus        NaT  \n",
      "996     0.00          China   Chengdu 2018-01-08  \n",
      "997     0.15  United States     Miami        NaT  \n",
      "998     0.00          China   Chengdu        NaT  \n",
      "999     0.31  United States     Miami        NaT  \n"
     ]
    }
   ],
   "source": [
    "print(data.head(10))  # for first 10\n",
    "print(data.tail(10))  # For ending 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.To get overall information of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of        EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[1000 rows x 14 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.To get detail infromation about data including all the columns and their data type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   EEID           1000 non-null   object        \n",
      " 1   Full Name      1000 non-null   object        \n",
      " 2   Job Title      1000 non-null   object        \n",
      " 3   Department     1000 non-null   object        \n",
      " 4   Business Unit  1000 non-null   object        \n",
      " 5   Gender         1000 non-null   object        \n",
      " 6   Ethnicity      1000 non-null   object        \n",
      " 7   Age            1000 non-null   int64         \n",
      " 8   Hire Date      1000 non-null   datetime64[ns]\n",
      " 9   Annual Salary  1000 non-null   int64         \n",
      " 10  Bonus %        1000 non-null   float64       \n",
      " 11  Country        1000 non-null   object        \n",
      " 12  City           1000 non-null   object        \n",
      " 13  Exit Date      85 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), int64(2), object(9)\n",
      "memory usage: 109.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.To get satistical information of data(Only of columns of data type excluidng objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Hire Date</th>\n",
       "      <th>Annual Salary</th>\n",
       "      <th>Bonus %</th>\n",
       "      <th>Exit Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.382000</td>\n",
       "      <td>2012-04-07 02:54:14.400000</td>\n",
       "      <td>113217.365000</td>\n",
       "      <td>0.088660</td>\n",
       "      <td>2016-11-02 18:04:14.117647104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>1992-01-09 00:00:00</td>\n",
       "      <td>40063.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1994-12-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>2007-02-14 00:00:00</td>\n",
       "      <td>71430.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014-12-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>2014-02-15 12:00:00</td>\n",
       "      <td>96557.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-05-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>2018-06-22 00:00:00</td>\n",
       "      <td>150782.250000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>2021-04-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>2021-12-26 00:00:00</td>\n",
       "      <td>258498.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2022-08-17 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.246981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53545.985644</td>\n",
       "      <td>0.117856</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age                   Hire Date  Annual Salary      Bonus %  \\\n",
       "count  1000.000000                        1000    1000.000000  1000.000000   \n",
       "mean     44.382000  2012-04-07 02:54:14.400000  113217.365000     0.088660   \n",
       "min      25.000000         1992-01-09 00:00:00   40063.000000     0.000000   \n",
       "25%      35.000000         2007-02-14 00:00:00   71430.250000     0.000000   \n",
       "50%      45.000000         2014-02-15 12:00:00   96557.000000     0.000000   \n",
       "75%      54.000000         2018-06-22 00:00:00  150782.250000     0.150000   \n",
       "max      65.000000         2021-12-26 00:00:00  258498.000000     0.400000   \n",
       "std      11.246981                         NaN   53545.985644     0.117856   \n",
       "\n",
       "                           Exit Date  \n",
       "count                             85  \n",
       "mean   2016-11-02 18:04:14.117647104  \n",
       "min              1994-12-18 00:00:00  \n",
       "25%              2014-12-25 00:00:00  \n",
       "50%              2019-05-23 00:00:00  \n",
       "75%              2021-04-09 00:00:00  \n",
       "max              2022-08-17 00:00:00  \n",
       "std                              NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.Finding null values in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      EEID  Full Name  Job Title  Department  Business Unit  Gender  \\\n",
      "0    False      False      False       False          False   False   \n",
      "1    False      False      False       False          False   False   \n",
      "2    False      False      False       False          False   False   \n",
      "3    False      False      False       False          False   False   \n",
      "4    False      False      False       False          False   False   \n",
      "..     ...        ...        ...         ...            ...     ...   \n",
      "995  False      False      False       False          False   False   \n",
      "996  False      False      False       False          False   False   \n",
      "997  False      False      False       False          False   False   \n",
      "998  False      False      False       False          False   False   \n",
      "999  False      False      False       False          False   False   \n",
      "\n",
      "     Ethnicity    Age  Hire Date  Annual Salary  Bonus %  Country   City  \\\n",
      "0        False  False      False          False    False    False  False   \n",
      "1        False  False      False          False    False    False  False   \n",
      "2        False  False      False          False    False    False  False   \n",
      "3        False  False      False          False    False    False  False   \n",
      "4        False  False      False          False    False    False  False   \n",
      "..         ...    ...        ...            ...      ...      ...    ...   \n",
      "995      False  False      False          False    False    False  False   \n",
      "996      False  False      False          False    False    False  False   \n",
      "997      False  False      False          False    False    False  False   \n",
      "998      False  False      False          False    False    False  False   \n",
      "999      False  False      False          False    False    False  False   \n",
      "\n",
      "     Exit Date  \n",
      "0        False  \n",
      "1         True  \n",
      "2         True  \n",
      "3         True  \n",
      "4         True  \n",
      "..         ...  \n",
      "995       True  \n",
      "996      False  \n",
      "997       True  \n",
      "998       True  \n",
      "999       True  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.Finding null values in data column wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEID               0\n",
      "Full Name          0\n",
      "Job Title          0\n",
      "Department         0\n",
      "Business Unit      0\n",
      "Gender             0\n",
      "Ethnicity          0\n",
      "Age                0\n",
      "Hire Date          0\n",
      "Annual Salary      0\n",
      "Bonus %            0\n",
      "Country            0\n",
      "City               0\n",
      "Exit Date        915\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.Handling Duplicates Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "995    False\n",
      "996    False\n",
      "997    False\n",
      "998    False\n",
      "999    False\n",
      "Length: 1000, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(data.duplicated())  # Checks row wise in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "995    False\n",
      "996    False\n",
      "997    False\n",
      "998    False\n",
      "999    False\n",
      "Length: 1000, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(data.duplicated(\"EEID\"))  # For particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    data.duplicated(\"EEID\").sum()\n",
    ")  # FInding sum of total number of duplicated in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[911 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.drop_duplicates(\"EEID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[911 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "data_drop = data.drop_duplicates(\"EEID\")\n",
    "print(data_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    data_drop[\"EEID\"].duplicated().sum()\n",
    ")  # To find out is there any duplicate value left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.Handling Null Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    r\"C:\\Users\\sayud\\OneDrive\\Desktop\\Data Science\\Pandas\\Datasets-main\\company1.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID   Name  gender  salary\n",
      "0  False  False   False    True\n",
      "1  False  False   False   False\n",
      "2  False  False    True   False\n",
      "3  False  False   False   False\n",
      "4  False   True   False   False\n",
      "5  False  False   False    True\n",
      "6  False  False   False   False\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull())  # Finding null values by each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEID      0\n",
      "Name      1\n",
      "gender    1\n",
      "salary    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())  # Sum of null values in any column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.1 Replacing the Null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F     NULL\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali   NULL  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05      NULL      M  25000.0\n",
      "5  EMP06     rohit      M     NULL\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "print(data.replace(np.nan, \"NULL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24400.0\n"
     ]
    }
   ],
   "source": [
    "print(data[\"salary\"].mean())  # Finding mean of salary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "data[\"salary\"] = data[\"salary\"].replace(\n",
    "    np.nan, 24400\n",
    ")  # Replacing NUll values of salary column with mean\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali      F  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05     rohit      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayud\\AppData\\Local\\Temp\\ipykernel_22168\\1866193408.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    data.fillna(method=\"bfill\")\n",
    ")  # For backward fill: Fills NULL values with the next non-NULL value in the column (moving downward)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali      M  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05    ayushi      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayud\\AppData\\Local\\Temp\\ipykernel_22168\\913193162.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    data.fillna(method=\"ffill\")\n",
    ")  # For forward fill: Fills NULL values with the previous non-NULL value in the column (moving forward)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.Column Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\n",
    "    r\"C:\\Users\\sayud\\OneDrive\\Desktop\\Data Science\\Pandas\\Datasets-main\\ESD.xlsx\"\n",
    ")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date Get Bonus  \n",
      "0     0.15  United States    Seattle 2021-10-16     Bonus  \n",
      "1     0.00          China  Chongqing        NaT  No Bonus  \n",
      "2     0.20  United States    Chicago        NaT     Bonus  \n",
      "3     0.07  United States    Chicago        NaT     Bonus  \n",
      "4     0.00  United States    Phoenix        NaT  No Bonus  \n",
      "5     0.00          China  Chongqing        NaT  No Bonus  \n",
      "6     0.10  United States    Phoenix        NaT     Bonus  \n",
      "7     0.00  United States      Miami 2021-05-20  No Bonus  \n",
      "8     0.06  United States     Austin        NaT     Bonus  \n",
      "9     0.00  United States    Chicago        NaT  No Bonus  \n"
     ]
    }
   ],
   "source": [
    "# Convert the `data` dictionary (or data source) into a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set the value of the new column 'Get Bonus' to 'No Bonus' where the 'Bonus %' column equals 0\n",
    "df.loc[(df[\"Bonus %\"] == 0), \"Get Bonus\"] = \"No Bonus\"\n",
    "\n",
    "# Set the value of another new column 'Gets Bonus' to 'Bonus' where the 'Bonus %' column is greater than 0\n",
    "df.loc[(df[\"Bonus %\"] > 0), \"Get Bonus\"] = \"Bonus\"\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Bonus\n",
      "No Bonus    525\n",
      "Bonus       475\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Get Bonus\"].value_counts())  # Counts number of Bonus and No bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date First name  \n",
      "0     0.15  United States    Seattle 2021-10-16      Emily  \n",
      "1     0.00          China  Chongqing        NaT   Theodore  \n",
      "2     0.20  United States    Chicago        NaT       Luna  \n",
      "3     0.07  United States    Chicago        NaT   Penelope  \n",
      "4     0.00  United States    Phoenix        NaT     Austin  \n",
      "5     0.00          China  Chongqing        NaT     Joshua  \n",
      "6     0.10  United States    Phoenix        NaT       Ruby  \n",
      "7     0.00  United States      Miami 2021-05-20       Luke  \n",
      "8     0.06  United States     Austin        NaT     Easton  \n",
      "9     0.00  United States    Chicago        NaT   Madeline  \n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'First name' by extracting the first word from 'Full Name'\n",
    "data[\"First name\"] = data[\"Full Name\"].str.split().str[0]\n",
    "\n",
    "# Print the DataFrame\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First name  Last Name  Salary EEID\n",
      "0       ross  tribbiani   20000   E1\n",
      "1     rachel       bing   40000   E2\n",
      "2     monica      green   25000   E7\n",
      "3       joey     geller   60000   E8\n",
      "4   chandler     buffay   33000   E4\n",
      "5     phoebe       bing   45000   E5\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\n",
    "    r\"C:\\Users\\sayud\\OneDrive\\Desktop\\Data Science\\Pandas\\Datasets-main\\practice_1.xlsx\"\n",
    ")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First name  Last Name  Salary EEID       Full Name\n",
      "0       ross  tribbiani   20000   E1   Rosstribbiani\n",
      "1     rachel       bing   40000   E2      Rachelbing\n",
      "2     monica      green   25000   E7     Monicagreen\n",
      "3       joey     geller   60000   E8      Joeygeller\n",
      "4   chandler     buffay   33000   E4  Chandlerbuffay\n",
      "5     phoebe       bing   45000   E5      Phoebebing\n"
     ]
    }
   ],
   "source": [
    "# Create a new column \"Full Name\" by combining the capitalized first name and the last name\n",
    "data[\"Full Name\"] = data[\"First name\"].str.capitalize() + \"\" + data[\"Last Name\"]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First name  Last Name  Salary EEID       Full Name    Bonus\n",
      "0       ross  tribbiani   20000   E1   Rosstribbiani   4000.0\n",
      "1     rachel       bing   40000   E2      Rachelbing   8000.0\n",
      "2     monica      green   25000   E7     Monicagreen   5000.0\n",
      "3       joey     geller   60000   E8      Joeygeller  12000.0\n",
      "4   chandler     buffay   33000   E4  Chandlerbuffay   6600.0\n",
      "5     phoebe       bing   45000   E5      Phoebebing   9000.0\n"
     ]
    }
   ],
   "source": [
    "# Added bonus column\n",
    "data[\"Bonus\"] = (data[\"Salary\"] / 100) * 20\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First name  Last Name  Salary EEID       Full Name    Bonus     Month\n",
      "0       ross  tribbiani   20000   E1   Rosstribbiani   4000.0   January\n",
      "1     rachel       bing   40000   E2      Rachelbing   8000.0  February\n",
      "2     monica      green   25000   E7     Monicagreen   5000.0     March\n",
      "3       joey     geller   60000   E8      Joeygeller  12000.0     April\n",
      "4   chandler     buffay   33000   E4  Chandlerbuffay   6600.0       May\n",
      "5     phoebe       bing   45000   E5      Phoebebing   9000.0      June\n"
     ]
    }
   ],
   "source": [
    "# Assigning a list of month names to the \"Month\" column of the DataFrame\n",
    "data[\"Month\"] = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\"]\n",
    "\n",
    "# Print the updated DataFrame to verify the \"Month\" column\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['Months'], dtype='object')\n",
      "     Months Shorts Month\n",
      "0   January          Jan\n",
      "1  February          Feb\n",
      "2     March          Mar\n",
      "3     April          Apr\n",
      "4       May          May\n",
      "5      June          Jun\n"
     ]
    }
   ],
   "source": [
    "# Example data dictionary\n",
    "data = {\"Months\": [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\"]}\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check the DataFrame structure and column names\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Ensure the column names are correct\n",
    "df.columns = df.columns.str.strip()  # Remove any extra spaces\n",
    "\n",
    "\n",
    "# Function to extract the first three characters\n",
    "def extract(value):\n",
    "    return value[0:3]\n",
    "\n",
    "\n",
    "# Applying the function to the \"Months\" column\n",
    "if \"Months\" in df.columns:\n",
    "    df[\"Shorts Month\"] = df[\"Months\"].map(extract)\n",
    "else:\n",
    "    print(\"Column 'Months' not found in DataFrame\")\n",
    "\n",
    "# Printing the final DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.Group By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\n",
    "    r\"C:\\Users\\sayud\\OneDrive\\Desktop\\Data Science\\Pandas\\Datasets-main\\ESD.xlsx\"\n",
    ")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Gender\n",
      "Department             \n",
      "Accounting           96\n",
      "Engineering         158\n",
      "Finance             120\n",
      "Human Resources     125\n",
      "IT                  241\n",
      "Marketing           120\n",
      "Sales               140\n"
     ]
    }
   ],
   "source": [
    "# Grouping the data by \"Department\"\n",
    "# .groupby(\"Department\") groups the rows by unique values in the \"Department\" column\n",
    "# .agg({\"Gender\": \"count\"}) applies the aggregation function \"count\" on the \"Gender\" column\n",
    "# This will count the number of rows in each group for the \"Gender\" column\n",
    "gp = data.groupby(\"Department\").agg({\"Gender\": \"count\"})\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                EEID\n",
      "Job Title                           \n",
      "Account Representative            21\n",
      "Analyst                           51\n",
      "Analyst II                        53\n",
      "Automation Engineer                7\n",
      "Business Partner                  19\n",
      "Cloud Infrastructure Architect    15\n",
      "Computer Systems Manager          21\n",
      "Controls Engineer                 15\n",
      "Development Engineer              19\n",
      "Director                         121\n",
      "Engineering Manager               20\n",
      "Enterprise Architect              18\n",
      "Field Engineer                    21\n",
      "HRIS Analyst                      16\n",
      "IT Coordinator                    11\n",
      "IT Systems Architect              12\n",
      "Manager                           98\n",
      "Network Administrator             10\n",
      "Network Architect                 18\n",
      "Network Engineer                   7\n",
      "Operations Engineer               12\n",
      "Quality Engineer                  20\n",
      "Service Desk Analyst              10\n",
      "Solutions Architect               15\n",
      "Sr. Account Representative         9\n",
      "Sr. Analyst                       70\n",
      "Sr. Business Partner              17\n",
      "Sr. Manger                       110\n",
      "System Administrator              15\n",
      "Systems Analyst                   15\n",
      "Technical Architect               17\n",
      "Test Engineer                     12\n",
      "Vice President                   105\n"
     ]
    }
   ],
   "source": [
    "# Grouping the data by Job Title and apllying aggregate function on EEID\n",
    "gp = data.groupby(\"Job Title\").agg({\"EEID\": \"count\"})\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        EEID\n",
      "Department      Gender      \n",
      "Accounting      Female    53\n",
      "                Male      43\n",
      "Engineering     Female    80\n",
      "                Male      78\n",
      "Finance         Female    69\n",
      "                Male      51\n",
      "Human Resources Female    64\n",
      "                Male      61\n",
      "IT              Female   119\n",
      "                Male     122\n",
      "Marketing       Female    57\n",
      "                Male      63\n",
      "Sales           Female    76\n",
      "                Male      64\n"
     ]
    }
   ],
   "source": [
    "# Grouping the data by both \"Department\" and \"Gender\"\n",
    "# .groupby([\"Department\", \"Gender\"]) groups the rows by unique combinations of \"Department\" and \"Gender\"\n",
    "# .agg({\"EEID\": \"count\"}) counts the number of occurrences (rows) in the \"EEID\" column for each group\n",
    "gp = data.groupby([\"Department\", \"Gender\"]).agg({\"EEID\": \"count\"})\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Annual Salary\n",
      "Country                     \n",
      "Brazil                258426\n",
      "China                 257194\n",
      "United States         258498\n"
     ]
    }
   ],
   "source": [
    "gp1 = data.groupby([\"Country\"]).agg({\"Annual Salary\": \"max\"})\n",
    "print(gp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Annual Salary\n",
      "Country       Gender               \n",
      "Brazil        Female         258426\n",
      "              Male           249506\n",
      "China         Female         249686\n",
      "              Male           257194\n",
      "United States Female         258498\n",
      "              Male           258081\n"
     ]
    }
   ],
   "source": [
    "gp1 = data.groupby([\"Country\", \"Gender\"]).agg({\"Annual Salary\": \"max\"})\n",
    "print(gp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.Merge,Concatenate and Joins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names  Age\n",
      "0    E01    Ajay   32\n",
      "1    E02    Raju   34\n",
      "2    E03  Ramesh   23\n",
      "3    E04   Sujay   54\n",
      "4    E05   Priya   23\n",
      "\n",
      "  Emp Id  Salary\n",
      "0    E01   45000\n",
      "1    E02   30000\n",
      "2    E03   35000\n",
      "3    E04   45000\n",
      "4    E05  320000\n"
     ]
    }
   ],
   "source": [
    "data1 = {\n",
    "    \"Emp Id\": [\"E01\", \"E02\", \"E03\", \"E04\", \"E05\"],\n",
    "    \"Names\": [\"Ajay\", \"Raju\", \"Ramesh\", \"Sujay\", \"Priya\"],\n",
    "    \"Age\": [32, 34, 23, 54, 23],\n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    \"Emp Id\": [\"E01\", \"E02\", \"E03\", \"E04\", \"E05\"],\n",
    "    \"Salary\": [45000, 30000, 35000, 45000, 320000],\n",
    "}\n",
    "df1=pd.DataFrame(data1)\n",
    "df2=pd.DataFrame(data2)\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names  Age  Salary\n",
      "0    E01    Ajay   32   45000\n",
      "1    E02    Raju   34   30000\n",
      "2    E03  Ramesh   23   35000\n",
      "3    E04   Sujay   54   45000\n",
      "4    E05   Priya   23  320000\n"
     ]
    }
   ],
   "source": [
    "#Merging to Data Normal Join\n",
    "print(pd.merge(df1,df2,on=\"Emp Id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names  Age\n",
      "0    E01    Ajay   32\n",
      "1    E02    Raju   34\n",
      "2    E03  Ramesh   23\n",
      "3    E04   Sujay   54\n",
      "4    E05   Priya   23\n",
      "\n",
      "  Emp Id  Salary\n",
      "0    E01   45000\n",
      "1    E07   30000\n",
      "2    E03   35000\n",
      "3    E06   45000\n",
      "4    E08  320000\n"
     ]
    }
   ],
   "source": [
    "data3 = {\n",
    "    \"Emp Id\": [\"E01\", \"E02\", \"E03\", \"E04\", \"E05\"],\n",
    "    \"Names\": [\"Ajay\", \"Raju\", \"Ramesh\", \"Sujay\", \"Priya\"],\n",
    "    \"Age\": [32, 34, 23, 54, 23],\n",
    "}\n",
    "\n",
    "data4 = {\n",
    "    \"Emp Id\": [\"E01\", \"E07\", \"E03\", \"E06\", \"E08\"],\n",
    "    \"Salary\": [45000, 30000, 35000, 45000, 320000],\n",
    "}\n",
    "df3=pd.DataFrame(data3)\n",
    "df4=pd.DataFrame(data4)\n",
    "print(df3)\n",
    "print()\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names  Age   Salary\n",
      "0    E01    Ajay   32  45000.0\n",
      "1    E02    Raju   34      NaN\n",
      "2    E03  Ramesh   23  35000.0\n",
      "3    E04   Sujay   54      NaN\n",
      "4    E05   Priya   23      NaN\n"
     ]
    }
   ],
   "source": [
    "#Merging to Data Left Join\n",
    "print(pd.merge(df3,df4,on=\"Emp Id\",how=\"left\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names   Age  Salary\n",
      "0    E01    Ajay  32.0   45000\n",
      "1    E07     NaN   NaN   30000\n",
      "2    E03  Ramesh  23.0   35000\n",
      "3    E06     NaN   NaN   45000\n",
      "4    E08     NaN   NaN  320000\n"
     ]
    }
   ],
   "source": [
    "#Merging to Data Right Join\n",
    "print(pd.merge(df3,df4,on=\"Emp Id\",how=\"right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names  Age  Salary\n",
      "0    E01    Ajay   32   45000\n",
      "1    E03  Ramesh   23   35000\n"
     ]
    }
   ],
   "source": [
    "#Merging to Data Inner Join\n",
    "print(pd.merge(df3,df4,on=\"Emp Id\",how=\"inner\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id   Names  Age\n",
      "0    E01    Ajay   32\n",
      "1    E02    Raju   34\n",
      "2    E03  Ramesh   23\n",
      "3    E04   Sujay   54\n",
      "4    E05   Priya   23\n",
      "\n",
      "  Emp Id     Names  Age\n",
      "0    E06    Aditya   32\n",
      "1    E07  Sanaskar   34\n",
      "2    E08     Rohit   23\n",
      "3    E09     Saish   54\n",
      "4    E10     Payal   23\n"
     ]
    }
   ],
   "source": [
    "data2 = {\n",
    "    \"Emp Id\": [\"E01\", \"E02\", \"E03\", \"E04\", \"E05\"],\n",
    "    \"Names\": [\"Ajay\", \"Raju\", \"Ramesh\", \"Sujay\", \"Priya\"],\n",
    "    \"Age\": [32, 34, 23, 54, 23],\n",
    "}\n",
    "data2 = {\n",
    "    \"Emp Id\": [\"E06\", \"E07\", \"E08\", \"E09\", \"E10\"],\n",
    "    \"Names\": [\"Aditya\", \"Sanaskar\", \"Rohit\", \"Saish\", \"Payal\"],\n",
    "    \"Age\": [32, 34, 23, 54, 23],\n",
    "}\n",
    "df1=pd.DataFrame(data1)\n",
    "df2=pd.DataFrame(data2)\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id     Names  Age\n",
      "0    E01      Ajay   32\n",
      "1    E02      Raju   34\n",
      "2    E03    Ramesh   23\n",
      "3    E04     Sujay   54\n",
      "4    E05     Priya   23\n",
      "0    E06    Aditya   32\n",
      "1    E07  Sanaskar   34\n",
      "2    E08     Rohit   23\n",
      "3    E09     Saish   54\n",
      "4    E10     Payal   23\n"
     ]
    }
   ],
   "source": [
    "#Concating two data\n",
    "print(pd.concat([df1,df2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.Compare Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fruits  Price  Quantity\n",
      "0      Apple    100         5\n",
      "1      Mango   1000        12\n",
      "2     Banana     50         5\n",
      "3  Pineapple     70         3\n"
     ]
    }
   ],
   "source": [
    "dict={\"Fruits\":[\"Apple\",\"Mango\",\"Banana\",\"Pineapple\"],\n",
    "      \"Price\":[100,1000,50,70],\n",
    "      \"Quantity\":[5,12,5,3]\n",
    "      }\n",
    "df1=pd.DataFrame(dict)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fruits  Price  Quantity\n",
      "0      Apple    100         5\n",
      "1      Mango   1000        12\n",
      "2     Banana     50         5\n",
      "3  Pineapple     70         3\n"
     ]
    }
   ],
   "source": [
    "#Copying df1 data in df2\n",
    "df2=df1.copy()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fruits  Price  Quantity\n",
      "0      Apple    120         7\n",
      "1      Mango   1200        12\n",
      "2     Banana     50         5\n",
      "3  Pineapple    100         3\n"
     ]
    }
   ],
   "source": [
    "#Updating price of index 0(i.e Apple)\n",
    "df2.loc[0,\"Price\"]=120\n",
    "df2.loc[1,\"Price\"]=1200\n",
    "df2.loc[3,\"Price\"]=100\n",
    "df2.loc[0,\"Quantity\"]=7\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Price         Quantity      \n",
      "     self   other     self other\n",
      "0   100.0   120.0      5.0   7.0\n",
      "1  1000.0  1200.0      NaN   NaN\n",
      "3    70.0   100.0      NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "print(df1.compare(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Price  Quantity\n",
      "0 self    100.0       5.0\n",
      "  other   120.0       7.0\n",
      "1 self   1000.0       NaN\n",
      "  other  1200.0       NaN\n",
      "3 self     70.0       NaN\n",
      "  other   100.0       NaN\n"
     ]
    }
   ],
   "source": [
    "# Compare df1 and df2, aligning differences row-wise (align_axis=0 is the default)\n",
    "# The `compare` method will:\n",
    "# - Show only rows with differences between df1 and df2.\n",
    "# - Include two columns for each differing value: 'self' (from df1) and 'other' (from df2).\n",
    "# - Align the differences row-wise.\n",
    "print(df1.compare(df2,align_axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fruits         Price         Quantity      \n",
      "    self other    self   other     self other\n",
      "0    NaN   NaN   100.0   120.0      5.0   7.0\n",
      "1    NaN   NaN  1000.0  1200.0      NaN   NaN\n",
      "2    NaN   NaN     NaN     NaN      NaN   NaN\n",
      "3    NaN   NaN    70.0   100.0      NaN   NaN\n",
      "\n",
      "  Price       Quantity      \n",
      "   self other     self other\n",
      "0   100   120        5     7\n",
      "1  1000  1200       12    12\n",
      "3    70   100        3     3\n"
     ]
    }
   ],
   "source": [
    "# Use the `compare` method with `keep_shape=True`\n",
    "# - This keeps the shape of the original DataFrame (same number of rows and columns).\n",
    "# - Rows and columns with no differences will show NaN.\n",
    "print(df1.compare(df2,keep_shape=True))\n",
    "print()\n",
    "# Use the `compare` method with `keep_equal=True`\n",
    "# - This keeps values that are equal in both DataFrames, in addition to showing differences.\n",
    "# - For equal values, the 'self' and 'other' columns will both display the common value.\n",
    "print(df1.compare(df2,keep_equal=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.Pivoting Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  keys   Names   House\n",
      "0   k1    John     red\n",
      "1   k2     Sam  yellow\n",
      "2   k3  Taylor   black\n",
      "3   k4    Dave  orange\n"
     ]
    }
   ],
   "source": [
    "dict={\"keys\":[\"k1\",\"k2\",\"k3\",\"k4\"],\n",
    "      \"Names\":[\"John\",\"Sam\",\"Taylor\",\"Dave\"],\n",
    "      \"House\":[\"red\",\"yellow\",\"black\",\"orange\"]\n",
    "}\n",
    "df=pd.DataFrame(dict)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Names</th>\n",
       "      <th>Dave</th>\n",
       "      <th>John</th>\n",
       "      <th>Sam</th>\n",
       "      <th>Taylor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keys</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yellow</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k4</th>\n",
       "      <td>orange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Names    Dave John     Sam Taylor\n",
       "keys                             \n",
       "k1        NaN  red     NaN    NaN\n",
       "k2        NaN  NaN  yellow    NaN\n",
       "k3        NaN  NaN     NaN  black\n",
       "k4     orange  NaN     NaN    NaN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the DataFrame\n",
    "# - index: 'keys' will become the row labels in the resulting pivot table\n",
    "# - columns: 'Names' will become the column labels\n",
    "# - values: 'House' will populate the cell values\n",
    "df.pivot(index=\"keys\", columns=\"Names\", values=\"House\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        House                    \n",
      "Names    Dave John     Sam Taylor\n",
      "keys                             \n",
      "k1        NaN  red     NaN    NaN\n",
      "k2        NaN  NaN  yellow    NaN\n",
      "k3        NaN  NaN     NaN  black\n",
      "k4     orange  NaN     NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "# Pivot the DataFrame with a list in 'values'\n",
    "# - index: 'keys' specifies the row labels in the pivot table\n",
    "# - columns: 'Names' specifies the column labels in the pivot table\n",
    "# - values: ['House'] allows selecting multiple columns for values (though we only have one here)\n",
    "print(df.pivot(index=\"keys\",columns=\"Names\",values=[\"House\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.Melting Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
